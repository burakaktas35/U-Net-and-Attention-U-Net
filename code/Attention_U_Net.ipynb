{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7ay2Bpw8u_a"
      },
      "source": [
        "#**Drive Mount**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jB5btjh8s3y"
      },
      "outputs": [],
      "source": [
        "#mount drive\n",
        "%cd ..\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "\n",
        "# list the contents of /mydrive\n",
        "!ls /mydrive\n",
        "\n",
        "#Navigate to /mydrive/Modern_Computer_Vision/\n",
        "%cd /mydrive/Modern_Computer_Vision/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1CiZmkz84wP"
      },
      "source": [
        "#**Library Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QTpyXx_8ykv"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "# from segmentation import build_unet, vgg16_unet, vgg19_unet, resnet50_unet, inception_resnetv2_unet, densenet121_unet\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IySGQn7-He9E"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3YK883-Hf8i"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKNe6kjx828B"
      },
      "source": [
        "#**GPU Check**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azTgFbQv81UX"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp2hsLeO875p"
      },
      "outputs": [],
      "source": [
        "if tf.test.gpu_device_name():\n",
        "  print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "  print(\"Please install GPU version of TF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrgVwtd08_If"
      },
      "source": [
        "#**CPU - GPU Usage Check**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_r0YtOl9AjP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxKsmXH39Ctw"
      },
      "source": [
        "#**Ram Check**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VThjwtre9CXD"
      },
      "outputs": [],
      "source": [
        "!cat /proc/meminfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUN1SApN9HSw"
      },
      "source": [
        "#**Data Gathering**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arrange according to your directory use only one of them"
      ],
      "metadata": {
        "id": "JdIVxAGvicCT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm1KdBdMa-8e"
      },
      "outputs": [],
      "source": [
        "base_directory = './NEW_100_5100dataset/'\n",
        "images_folder = os.path.join(base_directory, 'images')\n",
        "masks_folder = os.path.join(base_directory, 'masks')\n",
        "data = pd.read_csv(os.path.join(base_directory, 'output.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73ChJNi-a_e8"
      },
      "outputs": [],
      "source": [
        "base_directory = './NEW_3000data_5100dataset/3000_5100dataset_newmasks/'\n",
        "images_folder = os.path.join(base_directory, 'images')\n",
        "masks_folder = os.path.join(base_directory, 'masks')\n",
        "data = pd.read_csv(os.path.join(base_directory, 'output.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BgjuDLY6Xcz"
      },
      "outputs": [],
      "source": [
        "base_directory = './5100data_w_new_mask/'\n",
        "images_folder = os.path.join(base_directory, 'images')\n",
        "masks_folder = os.path.join(base_directory, 'masks')\n",
        "data = pd.read_csv(os.path.join(base_directory, 'meta_data.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eUsiSqeX8vb"
      },
      "outputs": [],
      "source": [
        "base_directory = './low_quality_data/'\n",
        "images_folder = os.path.join(base_directory, 'images')\n",
        "masks_folder = os.path.join(base_directory, 'masks')\n",
        "data = pd.read_csv(os.path.join(base_directory, 'meta_data.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFQ325w_8ni0"
      },
      "outputs": [],
      "source": [
        "base_directory = './High_Quality_Data/'\n",
        "images_folder = os.path.join(base_directory, 'images')\n",
        "masks_folder = os.path.join(base_directory, 'masks')\n",
        "data = pd.read_csv(os.path.join(base_directory, 'meta_data.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEBE0tzcoBUi"
      },
      "outputs": [],
      "source": [
        "base_directory = './High_Quality_Data/'\n",
        "images_folder = os.path.join(base_directory, 'images')\n",
        "masks_folder = os.path.join(base_directory, 'mask_reshape')\n",
        "data = pd.read_csv(os.path.join(base_directory, 'meta_data.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff-yj2jepUyT"
      },
      "outputs": [],
      "source": [
        "base_directory = './data/Forest_Segmented/Forest_Segmented/'\n",
        "images_folder = os.path.join(base_directory, 'images_old')\n",
        "masks_folder = os.path.join(base_directory, 'masks')\n",
        "data = pd.read_csv(os.path.join(base_directory, 'meta_data.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0J7ZXrI9HoZ"
      },
      "outputs": [],
      "source": [
        "base_directory = './data_v2/'\n",
        "images_folder = os.path.join(base_directory, 'images')\n",
        "masks_folder = os.path.join(base_directory, 'masks')\n",
        "data = pd.read_csv(os.path.join(base_directory, 'meta_data.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXfsxuaF9MN3"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL-SGbCA9NaZ"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2OkJKxM9W-5"
      },
      "outputs": [],
      "source": [
        "SIZE = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buNPJ_GzN18B"
      },
      "outputs": [],
      "source": [
        "def input_target_split(data,images_folder,masks_folder,dim):\n",
        "    dataset = []\n",
        "    for index, row in data.iterrows():\n",
        "        image = load_img(os.path.join(images_folder, row['images']), target_size=(dim,dim))\n",
        "        mask = load_img(os.path.join(masks_folder, row['masks']), target_size=(dim,dim), color_mode='grayscale')\n",
        "        image = img_to_array(image)\n",
        "        image = image/255.0\n",
        "        mask = img_to_array(mask)\n",
        "        mask = mask/255.0\n",
        "        dataset.append((image,mask))\n",
        "        print(f\"\\rProgress: {index}\",end='')\n",
        "    random.shuffle(dataset)\n",
        "    X, Y = zip(*dataset)\n",
        "\n",
        "    return np.array(X),np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qUDN_yJN5_u"
      },
      "outputs": [],
      "source": [
        "img_dim = 256\n",
        "X, Y = input_target_split(data,images_folder,masks_folder,img_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zEsDphQOASy"
      },
      "outputs": [],
      "source": [
        "print(\"Image Dimensions: \",X.shape)\n",
        "print(\"Mask Dimensions: \",Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8mhdCNpUzBR"
      },
      "outputs": [],
      "source": [
        "split_1 = round(X.shape[0]*0.70)\n",
        "split_2 = round(X.shape[0]*0.90)\n",
        "X_train = X[:split_1]\n",
        "Y_train = Y[:split_1]\n",
        "X_val = X[split_1:split_2]\n",
        "Y_val = Y[split_1:split_2]\n",
        "X_test = X[split_2:]\n",
        "Y_test = Y[split_2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aylhyrje17YV"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator()\n",
        "valgen = ImageDataGenerator()\n",
        "testgen = ImageDataGenerator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAUw6KVAU2-Y"
      },
      "outputs": [],
      "source": [
        "datagen.fit(X_train)\n",
        "valgen.fit(X_val)\n",
        "testgen.fit(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYXJnJI-ODsq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.10, random_state = 0)\n",
        "\n",
        "#Sanity check, view few mages\n",
        "import random\n",
        "import numpy as np\n",
        "image_number = random.randint(0, len(X_train))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.reshape(X_train[image_number], (256, 256, 3)), cmap='gray')\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.reshape(Y_train[image_number], (256, 256)), cmap='gray')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = X_train.shape[1]\n",
        "IMG_WIDTH  = X_train.shape[2]\n",
        "IMG_CHANNELS = X_train.shape[3]"
      ],
      "metadata": {
        "id": "lDER96bZdcof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6v5gOI2gOk8I"
      },
      "outputs": [],
      "source": [
        "#Parameters for model\n",
        "\n",
        "\n",
        "num_labels = 1  #Binary\n",
        "#input_shape = (IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)\n",
        "input_shape = (256,256,3)\n",
        "\n",
        "batch_size = 8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DsOLfR4Pi3P"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, regularizers\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_UI8OASO2Zn"
      },
      "outputs": [],
      "source": [
        "def conv_block(x, filter_size, size, dropout, batch_norm=False):\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(x)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(conv)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "\n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "\n",
        "    return conv\n",
        "\n",
        "\n",
        "def repeat_elem(tensor, rep):\n",
        "    # lambda function to repeat Repeats the elements of a tensor along an axis\n",
        "    #by a factor of rep.\n",
        "    # If tensor has shape (None, 256,256,3), lambda will return a tensor of shape\n",
        "    #(None, 256,256,6), if specified axis=3 and rep=2.\n",
        "\n",
        "     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),\n",
        "                          arguments={'repnum': rep})(tensor)\n",
        "\n",
        "\n",
        "def gating_signal(input, out_size, batch_norm=False):\n",
        "    \"\"\"\n",
        "    resize the down layer feature map into the same dimension as the up layer feature map\n",
        "    using 1x1 conv\n",
        "    :return: the gating feature map with the same dimension of the up layer feature map\n",
        "    \"\"\"\n",
        "    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n",
        "    if batch_norm:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def attention_block(x, gating, inter_shape):\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "\n",
        "# Getting the x signal to the same shape as the gating signal\n",
        "    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same')(x)  # 16\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "\n",
        "# Getting the gating signal to the same number of filters as the inter_shape\n",
        "    phi_g = layers.Conv2D(inter_shape, (1, 1), padding='same')(gating)\n",
        "    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3),\n",
        "                                 strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),\n",
        "                                 padding='same')(phi_g)  # 16\n",
        "\n",
        "    concat_xg = layers.add([upsample_g, theta_x])\n",
        "    act_xg = layers.Activation('relu')(concat_xg)\n",
        "    psi = layers.Conv2D(1, (1, 1), padding='same')(act_xg)\n",
        "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n",
        "\n",
        "    upsample_psi = repeat_elem(upsample_psi, shape_x[3])\n",
        "\n",
        "    y = layers.multiply([upsample_psi, x])\n",
        "\n",
        "    result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)\n",
        "    result_bn = layers.BatchNormalization()(result)\n",
        "    return result_bn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGPxLRH9PXHQ"
      },
      "outputs": [],
      "source": [
        "def Attention_UNet(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True):\n",
        "    '''\n",
        "    Attention UNet,\n",
        "\n",
        "    '''\n",
        "    # network structure\n",
        "    FILTER_NUM = 64 # number of basic filters for the first layer\n",
        "    FILTER_SIZE = 3 # size of the convolutional filter\n",
        "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
        "\n",
        "    inputs = layers.Input(input_shape, dtype=tf.float32)\n",
        "\n",
        "    # Downsampling layers\n",
        "    # DownRes 1, convolution + pooling\n",
        "    conv_128 = conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n",
        "    # DownRes 2\n",
        "    conv_64 = conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n",
        "    # DownRes 3\n",
        "    conv_32 = conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)\n",
        "    # DownRes 4\n",
        "    conv_16 = conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)\n",
        "    # DownRes 5, convolution only\n",
        "    conv_8 = conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    # UpRes 6, attention gated concatenation + upsampling + double residual convolution\n",
        "    gating_16 = gating_signal(conv_8, 8*FILTER_NUM, batch_norm)\n",
        "    att_16 = attention_block(conv_16, gating_16, 8*FILTER_NUM)\n",
        "    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_8)\n",
        "    up_16 = layers.concatenate([up_16, att_16], axis=3)\n",
        "    up_conv_16 = conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 7\n",
        "    gating_32 = gating_signal(up_conv_16, 4*FILTER_NUM, batch_norm)\n",
        "    att_32 = attention_block(conv_32, gating_32, 4*FILTER_NUM)\n",
        "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n",
        "    up_32 = layers.concatenate([up_32, att_32], axis=3)\n",
        "    up_conv_32 = conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 8\n",
        "    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)\n",
        "    att_64 = attention_block(conv_64, gating_64, 2*FILTER_NUM)\n",
        "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
        "    up_64 = layers.concatenate([up_64, att_64], axis=3)\n",
        "    up_conv_64 = conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 9\n",
        "    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)\n",
        "    att_128 = attention_block(conv_128, gating_128, FILTER_NUM)\n",
        "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
        "    up_128 = layers.concatenate([up_128, att_128], axis=3)\n",
        "    up_conv_128 = conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # 1*1 convolutional layers\n",
        "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    conv_final = layers.Activation('sigmoid')(conv_final)  #Change to softmax for multichannel\n",
        "\n",
        "    # Model integration\n",
        "    model = models.Model(inputs, conv_final, name=\"Attention_UNet\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVmbYhODP3Bo"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
        "\n",
        "\n",
        "def iou_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "\n",
        "def iou_coef_loss(y_true, y_pred):\n",
        "    return -iou_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78lsluDUD4mV"
      },
      "outputs": [],
      "source": [
        "#start2 = datetime.datetime.now()\n",
        "#stop2 = datetime.datetime.now()\n",
        "#Execution time of the model\n",
        "#execution_time_Att_Unet = stop2-start2\n",
        "#print(\"Attention UNet execution time is: \", execution_time_Att_Unet)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "import datetime\n",
        "\n",
        "att_unet_model = Attention_UNet(input_shape)\n",
        "\n",
        "#att_unet_model.compile(optimizer=Adam(lr = 1e-3), loss=['binary_crossentropy'], metrics=['accuracy', iou_coef])\n",
        "att_unet_model.compile(optimizer=Adam(lr = 1e-3), loss=dice_coef_loss, metrics=['accuracy', iou_coef])\n",
        "\n",
        "print(att_unet_model.summary())\n"
      ],
      "metadata": {
        "id": "RId2MKHvdmLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NZsDaoRPPXH"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import Adam\n",
        "import datetime\n",
        "\n",
        "att_unet_model = Attention_UNet(input_shape)\n",
        "\n",
        "#att_unet_model.compile(optimizer=Adam(lr = 1e-3), loss=['binary_crossentropy'], metrics=['accuracy', iou_coef])\n",
        "att_unet_model.compile(optimizer=Adam(lr = 1e-3), loss=dice_coef_loss, metrics=['accuracy', iou_coef])\n",
        "\n",
        "print(att_unet_model.summary())\n",
        "\n",
        "att_unet_history = att_unet_model.fit(X_train, Y_train,\n",
        "                    verbose=1,\n",
        "                    batch_size = batch_size,\n",
        "                    validation_data=(X_val, Y_val),\n",
        "                    shuffle=False,\n",
        "                    epochs=50)\n",
        "att_unet_model.save('Attention_UNet_50epochs.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ1pK0GoSnnP"
      },
      "outputs": [],
      "source": [
        "# Plotting our loss charts\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use the History object we created to get our saved performance results\n",
        "history_dict = att_unet_history.history\n",
        "\n",
        "# Extract the loss and validation losses\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "# Get the number of epochs and create an array up to that number using range()\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "#plt.ylim(0, 3)\n",
        "\n",
        "# Plot line charts for both Validation and Training Loss\n",
        "line1 = plt.plot(epochs, val_loss_values, label='Validation Loss')\n",
        "line2 = plt.plot(epochs, loss_values, label='Training Loss')\n",
        "plt.setp(line1, linewidth=2.0, marker = '+', markersize=10.0)\n",
        "plt.setp(line2, linewidth=2.0, marker = '4', markersize=10.0)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5DqfJIDSors"
      },
      "outputs": [],
      "source": [
        "# Plotting our accuracy charts\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = att_unet_history.history\n",
        "\n",
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "epochs = range(1, len(acc_values) + 1)\n",
        "\n",
        "line1 = plt.plot(epochs, val_acc_values, label='Validation Accuracy')\n",
        "line2 = plt.plot(epochs, acc_values, label='Training Accuracy')\n",
        "plt.setp(line1, linewidth=2.0, marker = '+', markersize=10.0)\n",
        "plt.setp(line2, linewidth=2.0, marker = '4', markersize=10.0)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5re8eYFSpz9"
      },
      "outputs": [],
      "source": [
        "# Plotting our loss charts\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use the History object we created to get our saved performance results\n",
        "history_dict = att_unet_history.history\n",
        "\n",
        "# Extract the loss and validation losses\n",
        "loss_values = history_dict['iou_coef']\n",
        "val_loss_values = history_dict['val_iou_coef']\n",
        "\n",
        "# Get the number of epochs and create an array up to that number using range()\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "# Plot line charts for both Validation and Training Loss\n",
        "line1 = plt.plot(epochs, val_loss_values, label='Validation IoU')\n",
        "line2 = plt.plot(epochs, loss_values, label='Training IoU')\n",
        "plt.setp(line1, linewidth=2.0, marker = '+', markersize=10.0)\n",
        "plt.setp(line2, linewidth=2.0, marker = '4', markersize=10.0)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IoU')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "515Ieuo8StHf"
      },
      "outputs": [],
      "source": [
        "att_unet_model.save(\"Attention_U-Net_Model.h5\")\n",
        "print(\"Model Saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqioibqJStTP"
      },
      "outputs": [],
      "source": [
        "att_unet_model.save_weights(\"Attention_U-Net_Model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFI5fWVISunQ"
      },
      "outputs": [],
      "source": [
        "att_unet_model.load_weights(\"Attention_U-Net_Model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk7yDM_GSwaF"
      },
      "outputs": [],
      "source": [
        "att_unet_model.save(\"Attention_U-Net_Model.hdf5\")\n",
        "print(\"Model Saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9jouo3aSyOD"
      },
      "outputs": [],
      "source": [
        "att_unet_model.save_weights(\"Attention_U-Net_Model.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Fb_dFenSyS-"
      },
      "outputs": [],
      "source": [
        "att_unet_model.save_weights(\"Attention_U-Net_Model.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zko8YGc5UjXQ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (15 , 9))\n",
        "result = att_unet_model.predict(X_test)\n",
        "output = result[0]\n",
        "output[output >= 0.5] = 1\n",
        "output[output < 0.5] = 0\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(X_test[0])\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(np.squeeze(Y_test[0]))\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(np.squeeze(output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZdJ1IJOUfvC"
      },
      "outputs": [],
      "source": [
        "f, axarr = plt.subplots(10,3,figsize=(20, 60))\n",
        "\n",
        "for i in range(0,10):\n",
        "    output = result[i]\n",
        "    output[output >= 0.5] = 1\n",
        "    output[output < 0.5] = 0\n",
        "\n",
        "    axarr[i,0].imshow(X_test[i])\n",
        "    axarr[i,0].title.set_text('Original Image')\n",
        "    axarr[i,1].imshow(np.squeeze(Y_test[i]))\n",
        "    axarr[i,1].title.set_text('Actual Mask')\n",
        "    axarr[i,2].imshow(np.squeeze(output))\n",
        "    axarr[i,2].title.set_text('Predicted Mask')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNyDoAvin5dD"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "out = cv2.imread(\"aerial-view-rural-road-green-corn-field-beautiful-abstract-geometric-shapes-agricultural-parcels-lush-landscape-countryside-137194914.jpg\", cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(out)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}